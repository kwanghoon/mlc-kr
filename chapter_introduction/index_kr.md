# 소개
:label:`chap_introduction`

머신러닝 애플리케이션은 의심할 여지 없이 어디서나 볼 수 있게 되었습니다. 우리는 자연어 처리와 음성 인식 모델로 구동되는 스마트 홈 기기를 사용하고, 컴퓨터 비전 모델은 자율 주행의 백본 역할을 하며, 추천 시스템은 우리가 탐색할 때 새로운 콘텐츠를 발견하도록 도와줍니다.
AI 앱이 실행되는 풍부한 환경들을 관찰하는 것도 꽤 재미있습니다. 추천 시스템은 일반적으로 서비스를 제공하는 기업의 클라우드 플랫폼에 배포됩니다. 자율 주행에 대해 이야기할 때, 우리 머릿속에 자연스럽게 떠오르는 것은 차량에 탑재된 강력한 GPU나 특수 컴퓨팅 장치입니다. 우리는 스마트폰의 지능형 애플리케이션을 사용하여 정원의 꽃을 인식하고 그것을 돌보는 방법을 배웁니다. 점점 더 많은 IoT 센서들도 그 작은 칩 안에 AI를 내장하고 있습니다.
이러한 환경들을 더 깊이 들여다보면, 훨씬 더 많은 다양성이 있습니다. 같은 범주에 속하는 환경들(예: 클라우드)에서도 하드웨어(ARM 또는 x86), 운영 체제, 컨테이너 실행 환경, 런타임 라이브러리 변형, 또는 관련된 가속기의 종류에 대한 질문들이 있습니다.
스마트 머신러닝 모델을 개발 단계에서 이러한 프로덕션 환경으로 가져오기 위해서는 상당한 노력이 필요합니다. 우리가 가장 익숙한 환경(예: GPU)에서조차, 머신러닝 모델을 비표준 연산 세트를 사용하도록 확장하려면 상당한 엔지니어링 작업이 필요합니다.
위의 많은 예들은 머신러닝 추론(inference)과 관련이 있습니다 — 모델 가중치를 얻은 후 예측을 수행하는 과정입니다. 우리는 또한 학습 프로세스 자체를 다양한 환경에 배포하는 중요한 추세를 보기 시작했습니다. 이러한 애플리케이션들은 프라이버시 보호를 위해 모델 업데이트를 사용자 기기에 로컬로 유지하거나 분산된 노드 클러스터로 모델 학습을 확장해야 하는 필요성에서 비롯됩니다. 다양한 모델링 선택과 추론/학습 시나리오는 머신러닝의 프로덕션화에 더 많은 복잡성을 추가합니다.


![ML 배포의 격차](../img/intro-gap.png)
:label:`fig_intro_gap`


이 강좌는 머신러닝을 개발 단계에서 프로덕션 환경으로 가져오는 주제를 다룹니다. 우리는 ML 프로덕션화 과정을 용이하게 하는 다양한 방법들을 학습할 것입니다. 머신러닝 프로덕션화는 여전히 개방적이고 활발한 분야이며, 머신러닝 및 시스템 커뮤니티에서 새로운 기술들이 개발되고 있습니다. 그럼에도 불구하고, 우리는 공통 주제들이 나타나기 시작하는 것을 보게 되며, 이것이 이 강좌의 주제가 됩니다.

## ML 컴파일이란 무엇인가

머신러닝 컴파일(MLC)은 머신러닝 실행을 개발 형태에서 배포 형태로 변환하고 최적화하는 과정입니다.

**개발 형태**는 머신러닝 모델을 개발할 때 사용하는 요소들의 집합을 말합니다. 일반적인 개발 형태는 PyTorch, TensorFlow, JAX와 같은 일반적인 프레임워크로 작성된 모델 설명과 그와 관련된 가중치를 포함합니다.

**배포 형태**는 머신러닝 애플리케이션을 실행하는 데 필요한 요소들의 집합을 말합니다. 일반적으로 머신러닝 모델의 각 단계를 지원하기 위해 생성된 코드 세트, 리소스(예: 메모리)를 관리하는 루틴, 애플리케이션 개발 환경에 대한 인터페이스(예: 안드로이드 앱용 Java API)를 포함합니다.


![개발 및 배포 형태](../img/dev-deploy-form.png)
:label:`fig_dev_deploy_form`


우리는 "컴파일"이라는 용어를 사용하는데, 이 과정은 전통적인 컴파일러가 하는 일과 매우 유사하게 볼 수 있기 때문입니다 — 컴파일러는 개발 형태의 애플리케이션을 가져와 배포 가능한 라이브러리로 컴파일합니다. 그러나 머신러닝 컴파일은 여전히 전통적인 컴파일과 여러 면에서 다릅니다.

우선, 이 과정이 반드시 코드 생성을 포함하는 것은 아닙니다. 예를 들어, 배포 형태는 미리 정의된 라이브러리 함수들의 집합일 수 있으며, ML 컴파일은 단지 개발 형태를 이러한 라이브러리 호출로 변환하기만 합니다. 직면하는 과제와 솔루션의 집합도 상당히 다릅니다. 그래서 머신러닝 컴파일을 전통적인 컴파일과는 독립적으로 자체 주제로 연구하는 것이 가치가 있습니다. 그럼에도 불구하고, 머신러닝 컴파일에서도 전통적인 컴파일 개념 중 일부 유용한 것들을 발견할 수 있습니다.

머신러닝 컴파일 과정은 일반적으로 몇 가지 목표를 가지고 있습니다:

**통합 및 의존성 최소화.** 배포 프로세스는 일반적으로 통합을 포함합니다 — 배포 앱에 필요한 요소들을 함께 조립하는 것입니다. 예를 들어, 안드로이드 카메라 앱이 꽃을 분류할 수 있도록 하려면, 꽃 분류 모델을 실행하는 필요한 코드를 조립해야 하지만, 모델과 관련 없는 다른 부분들(예: NLP 애플리케이션용 임베딩 테이블 조회 코드는 포함할 필요가 없음)은 반드시 필요하지 않습니다. 필요한 의존성을 조립하고 최소화하는 능력은 전체 크기를 줄이고 앱을 배포할 수 있는 환경의 수를 늘리는 데 매우 중요합니다.

**하드웨어 네이티브 가속 활용.** 각 배포 환경은 고유한 네이티브 가속 기술 세트를 가지고 있으며, 그 중 많은 것들이 특히 ML을 위해 개발되었습니다. 머신러닝 컴파일 프로세스의 한 가지 목표는 해당 하드웨어의 네이티브 가속을 활용하는 것입니다. 우리는 네이티브 가속 라이브러리를 호출하는 배포 형태를 구축하거나 TensorCore와 같은 네이티브 명령어를 활용하는 코드를 생성함으로써 이를 수행할 수 있습니다.

**일반적인 최적화.** 동일한 모델 실행을 수행하는 여러 동등한 방법들이 있습니다. MLC의 공통 주제는 메모리 사용을 최소화하거나 실행 효율성을 향상시키는 방식으로 모델 실행을 변환하는 다양한 형태의 최적화입니다.

이러한 목표들 사이에 엄격한 경계는 없습니다. 예를 들어, 통합과 하드웨어 가속도 일반적으로 최적화로 볼 수 있습니다. 특정 애플리케이션 시나리오에 따라, 우리는 일부 소스 모델과 프로덕션 환경의 쌍에 관심이 있을 수 있고, 또는 여러 곳에 배포하고 가장 비용 효율적인 변형을 선택하는 데 관심이 있을 수 있습니다.

중요한 것은, MLC가 반드시 단일의 안정적인 솔루션을 나타내는 것은 아니라는 점입니다. 사실, 많은 MLC 실무는 하드웨어와 모델 세트의 양이 증가함에 따라 다양한 배경을 가진 개발자들과의 협업을 포함합니다. 하드웨어 개발자는 최신 하드웨어 네이티브 가속에 대한 지원이 필요하고, 머신러닝 엔지니어는 추가 최적화를 가능하게 하는 것을 목표로 하며, 과학자들은 새로운 모델을 도입합니다.

## 왜 ML 컴파일을 공부해야 하는가

이 강좌는 머신러닝 컴파일을 방법론과 공통 방법론과 함께 제공되는 도구들의 모음으로 가르칩니다. 이러한 도구들은 일반적인 머신러닝 시스템과 함께 작동하거나 그 안에서 작동하여 사용자에게 가치를 제공할 수 있습니다.
현장에서 ML을 다루는 머신러닝 엔지니어들에게, MLC는 원칙적인 방식으로 문제를 해결하는 기본 도구를 제공합니다. 이는 특정 관심 모델의 배포 및 메모리 효율성을 개선하기 위해 어떤 방법론을 취할 수 있는지, 그리고 모델의 단일 부분을 최적화한 경험을 보다 일반적인 엔드투엔드 솔루션으로 일반화하는 방법 같은 질문에 답하는 데 도움이 됩니다.
머신러닝 과학자들에게, MLC는 모델을 프로덕션으로 가져오는 데 필요한 단계들에 대한 보다 심층적인 관점을 제공합니다. 일부 복잡성은 머신러닝 프레임워크 자체에 의해 숨겨져 있지만, 새로운 모델 커스터마이징을 통합하기 시작하거나 프레임워크에서 잘 지원되지 않는 플랫폼으로 모델을 푸시할 때 여전히 과제가 남아 있습니다. ML 컴파일은 또한 ML 과학자들에게 내부 원리를 이해하고 왜 내 모델이 예상만큼 빠르게 실행되지 않는지, 배포를 더 효과적으로 만들기 위해 무엇을 할 수 있는지와 같은 질문에 답할 기회를 제공합니다.
하드웨어 제공업체에게, MLC는 그들이 구축한 하드웨어를 최대한 활용하기 위한 머신러닝 소프트웨어 스택을 구축하는 일반적인 접근 방식을 제공합니다. 또한 전체 엔지니어링 노력을 최소화하면서 새로운 세대의 하드웨어 및 모델 개발을 따라잡기 위해 소프트웨어 최적화를 자동화하는 도구를 제공합니다.
중요한 것은, 머신러닝 컴파일 기술이 독립적으로 사용되는 것이 아니라는 점입니다. 많은 MLC 기술들이 일반적인 머신러닝 프레임워크와 머신러닝 배포 플로우에 적용되었거나 통합되고 있습니다. MLC는 머신러닝 소프트웨어 생태계의 API, 아키텍처, 연결 컴포넌트를 형성하는 데 점점 더 중요한 역할을 하고 있습니다.
마지막으로, MLC를 배우는 것 자체가 재미있습니다. 현대적인 머신러닝 컴파일 도구 세트를 사용하면, 머신러닝 모델의 단계들을 높은 수준에서부터 코드 최적화, 베어 메탈까지 들어갈 수 있습니다. 여기서 무슨 일이 일어나는지 엔드투엔드로 이해하고 이를 사용하여 우리의 문제를 해결하는 것은 정말 재미있습니다.

## ML 컴파일의 핵심 요소


![MLC 요소](../img/mlc-elements.png)
:label:`fig_mlc_elements`

이전 섹션에서는 머신러닝 컴파일을 높은 수준에서 논의했습니다. 이제 머신러닝 컴파일의 핵심 요소 중 일부를 더 깊이 살펴보겠습니다. 2층 신경망 모델 실행의 예를 검토하는 것부터 시작하겠습니다.

이 특정 모델에서는 입력 이미지의 픽셀을 평탄화하여 벡터로 만들고, 그런 다음 입력 이미지를 `relu` 활성화 함수를 사용하여 길이 200의 벡터로 투영하는 선형 변환을 적용합니다. 마지막으로, 이를 길이 10의 벡터로 매핑하며, 벡터의 각 요소는 이미지가 해당 특정 클래스에 속할 가능성에 해당합니다.

**텐서**는 실행에서 가장 중요한 첫 번째 요소입니다. 텐서는 신경망 모델 실행의 입력, 출력 및 중간 결과를 나타내는 다차원 배열입니다.

**텐서 함수** 신경망의 "지식"은 가중치와 텐서를 입력으로 받아 텐서를 출력하는 일련의 계산에 인코딩되어 있습니다. 우리는 이러한 계산을 텐서 함수라고 부릅니다. 특히, 텐서 함수는 신경망 계산의 단일 단계에 해당할 필요가 없습니다. 계산의 일부 또는 전체 엔드투엔드 계산도 텐서 함수로 볼 수 있습니다.

![텐서 함수 변환으로서의 MLC 프로세스 예](../img/mlc-elem-transform.png)
:label:`fig_mlc_elem_transform`



특정 관심 환경에서 모델 실행을 구현하는 여러 방법이 있습니다. 위의 예는 한 가지 예를 보여줍니다. 특히 두 가지 차이점이 있습니다:
첫째, 첫 번째 선형 계산과 relu 계산이 `linear_relu` 함수로 접혀 있습니다. 이제 특정 linear_relu의 상세한 구현이 있습니다. 물론, 실제 사용 사례에서는 `linear_relu`가 모든 종류의 코드 최적화 기술을 사용하여 구현될 것이며, 그 중 일부는 강의의 후반부에서 다룰 것입니다.
MLC는 왼쪽의 것을 오른쪽으로 변환하는 과정입니다. 다양한 설정에서, 이것은 수동으로, 일부 자동 변환 도구를 사용하여, 또는 둘 다를 사용하여 수행될 수 있습니다.

### 주의사항: 추상화와 구현

우리가 주목할 수 있는 한 가지는 텐서 함수를 표현하는 여러 다른 방법을 사용한다는 것입니다. 예를 들어, `linear_relu`는 그래프의 컴팩트한 박스로 표현되거나 루프 중첩 표현으로 표현될 수 있음을 보여줍니다.

![추상화와 구현](../img/mlc-abstraction-impl.png)
:label:`fig_mlc_abstraction_impl`


우리는 **추상화**를 사용하여 동일한 텐서 함수를 표현하는 방법을 나타냅니다. 다른 추상화는 일부 세부 사항을 명시하면서 다른 **구현** 세부 사항을 생략할 수 있습니다. 예를 들어, `linear_relu`는 또 다른 다른 for 루프를 사용하여 구현될 수 있습니다.

**추상화**와 **구현**은 아마도 모든 컴퓨터 시스템에서 가장 중요한 키워드일 것입니다. 추상화는 "무엇"을 할 것인지를 명시하고, 구현은 "어떻게" 할 것인지를 제공합니다. 특정한 경계는 없습니다. 우리가 어떻게 보느냐에 따라, for 루프 자체도 추상화로 볼 수 있는데, 그것은 파이썬 인터프리터를 사용하여 구현되거나 네이티브 어셈블리 코드로 컴파일될 수 있기 때문입니다.

MLC는 사실상 동일하거나 다른 추상화 하에서 텐서 함수를 변환하고 조립하는 과정입니다. 우리는 텐서 함수에 대한 다양한 종류의 추상화와 그것들이 머신러닝 배포의 과제를 해결하기 위해 어떻게 함께 작동할 수 있는지를 학습할 것입니다.

## 요약

- 머신러닝 컴파일의 목표
    - 통합 및 의존성 최소화
    - 하드웨어 네이티브 가속 활용
    - 일반적인 최적화
- ML 컴파일을 공부하는 이유
    - ML 배포 솔루션 구축
    - 기존 ML 프레임워크에 대한 심층적인 관점
    - 신흥 하드웨어를 위한 소프트웨어 스택 구축
- ML 컴파일의 핵심 요소
    - 텐서와 텐서 함수
    - 추상화와 구현은 사고를 위한 유용한 도구
